{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Skills + Google Gemini\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sergioc/ai-skills/blob/main/examples/notebooks/gemini_colab.ipynb)\n",
    "\n",
    "This notebook demonstrates how to use AI Skills with Google Gemini models.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install aiskills[gemini,search] -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure API Key\n",
    "\n",
    "Get your API key from [Google AI Studio](https://makersuite.google.com/app/apikey)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# In Colab, you can also use Secrets\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"GEMINI_API_KEY\"] = userdata.get(\"GEMINI_API_KEY\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if \"GEMINI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GEMINI_API_KEY\"] = getpass(\"Enter your Gemini API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start: 3 Lines of Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiskills.integrations import create_gemini_client\n",
    "\n",
    "client = create_gemini_client()\n",
    "response = client.chat(\"Help me debug a memory leak in Python\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How It Works\n",
    "\n",
    "Gemini's automatic function calling:\n",
    "1. You send a message to Gemini\n",
    "2. Gemini recognizes it needs a skill and calls the appropriate function\n",
    "3. The function executes locally (searches your skills library)\n",
    "4. Results are automatically fed back to Gemini\n",
    "5. Gemini generates the final response\n",
    "\n",
    "## Multi-Turn Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a chat session\n",
    "chat = client.start_chat()\n",
    "\n",
    "# First message\n",
    "response1 = chat.send_message(\"What skills do you have for testing?\")\n",
    "print(\"Response 1:\")\n",
    "print(response1.text)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Follow-up\n",
    "response2 = chat.send_message(\"Tell me more about the Python debugging one\")\n",
    "print(\"Response 2:\")\n",
    "print(response2.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Tools\n",
    "\n",
    "The Gemini integration provides these tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the tools\n",
    "tools = client.get_tools()\n",
    "print(\"Available tools:\")\n",
    "for tool in tools:\n",
    "    print(f\"  - {tool.__name__}: {tool.__doc__.split(chr(10))[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Skill Operations\n",
    "\n",
    "You can also call skill operations directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available skills\n",
    "skills = client.list_skills()\n",
    "print(f\"Found {len(skills)} skills:\\n\")\n",
    "for skill in skills[:5]:\n",
    "    print(f\"  - {skill['name']}: {skill['description'][:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for skills\n",
    "results = client.search_skills(\"docker kubernetes\")\n",
    "print(f\"Found {results.total} skills:\\n\")\n",
    "for r in results.results:\n",
    "    print(f\"  - {r['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a skill directly\n",
    "result = client.use_skill(\"help me write unit tests in Python\")\n",
    "if result.success:\n",
    "    print(f\"Using skill: {result.skill_name}\")\n",
    "    print(f\"\\nContent preview:\\n{result.content[:500]}...\")\n",
    "else:\n",
    "    print(f\"Error: {result.error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pre-configured Model\n",
    "\n",
    "For more control, get the model directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiskills.integrations import create_gemini_model\n",
    "\n",
    "# Get a GenerativeModel with tools attached\n",
    "model = create_gemini_model(model_name=\"gemini-1.5-flash\")  # Faster model\n",
    "\n",
    "# Use it directly\n",
    "chat = model.start_chat(enable_automatic_function_calling=True)\n",
    "response = chat.send_message(\"How do I optimize database queries?\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Function Handling\n",
    "\n",
    "For complete control over function execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiskills.integrations import get_gemini_tools, GeminiSkills\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Get tools\n",
    "tools = get_gemini_tools()\n",
    "\n",
    "# Create model WITHOUT auto function calling\n",
    "model = genai.GenerativeModel(\n",
    "    model_name='gemini-1.5-pro',\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "# Start chat without auto-calling\n",
    "chat = model.start_chat(enable_automatic_function_calling=False)\n",
    "\n",
    "response = chat.send_message(\"What skills do you have for Python?\")\n",
    "\n",
    "# Check for function calls\n",
    "for part in response.parts:\n",
    "    if hasattr(part, 'function_call'):\n",
    "        fn = part.function_call\n",
    "        print(f\"Function call: {fn.name}\")\n",
    "        print(f\"Arguments: {dict(fn.args)}\")\n",
    "    elif hasattr(part, 'text'):\n",
    "        print(f\"Text: {part.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Code Review Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiskills.integrations import create_gemini_client\n",
    "\n",
    "client = create_gemini_client()\n",
    "\n",
    "code_to_review = '''\n",
    "def fetch_all_users():\n",
    "    users = []\n",
    "    for i in range(10000):\n",
    "        response = requests.get(f\"https://api.example.com/users/{i}\")\n",
    "        if response.status_code == 200:\n",
    "            users.append(response.json())\n",
    "    return users\n",
    "'''\n",
    "\n",
    "response = client.chat(f\"Review this code and suggest improvements:\\n```python\\n{code_to_review}\\n```\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Try different Gemini models: `gemini-1.5-pro`, `gemini-1.5-flash`\n",
    "- Install more skills from GitHub\n",
    "- Create your own skills\n",
    "\n",
    "For more information, see the [documentation](https://github.com/sergioc/ai-skills)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
